<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">4 posts tagged with &quot;PyTorch&quot; | Sam&#x27;s Portfolio</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ash3327.github.io/personalblog/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ash3327.github.io/personalblog/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ash3327.github.io/personalblog/blog/tags/py-torch"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="4 posts tagged with &quot;PyTorch&quot; | Sam&#x27;s Portfolio"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/personalblog/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://ash3327.github.io/personalblog/blog/tags/py-torch"><link data-rh="true" rel="alternate" href="https://ash3327.github.io/personalblog/blog/tags/py-torch" hreflang="en"><link data-rh="true" rel="alternate" href="https://ash3327.github.io/personalblog/blog/tags/py-torch" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/personalblog/blog/rss.xml" title="Sam&#39;s Portfolio RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/personalblog/blog/atom.xml" title="Sam&#39;s Portfolio Atom Feed">




<link rel="alternate" type="application/rss+xml" href="/personalblog/blog_old/rss.xml" title="Sam&#39;s Portfolio RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/personalblog/blog_old/atom.xml" title="Sam&#39;s Portfolio Atom Feed">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"><link rel="stylesheet" href="/personalblog/assets/css/styles.cbb2b67f.css">
<script src="/personalblog/assets/js/runtime~main.e935865b.js" defer="defer"></script>
<script src="/personalblog/assets/js/main.58ab2afb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/personalblog/"><b class="navbar__title text--truncate">SamKHT</b></a><a class="navbar__item navbar__link" href="/personalblog/life-in-weeks">Life in Weeks 生命倒計時</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/personalblog/blog">Blog 博客</a><a class="navbar__item navbar__link" href="/personalblog/docs/base/intro">Prog 編程</a><a class="navbar__item navbar__link" href="/personalblog/docs/algo/intro/">Algo 算法</a><a class="navbar__item navbar__link" href="/personalblog/docs/ai/intro">AI 人工智能</a><a class="navbar__item navbar__link" href="/personalblog/docs/interests/intro">Interests 興趣</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/ash3327" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-github fa-brands fa-xl" aria-label="GitHub"></a><a href="https://linkedin.com/in/khtam-51a008256" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-linkedin fa-brands fa-xl" aria-label="LinkedIn"></a><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/hand-gesture-recognition">Project: General Hand Gesture Recognition</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/oasis-event-planning-app">Project: Event-Planning App &quot;Oasis&quot;</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/p2p-communication-app">Project: P2P Communication App</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/vision-transformer-analysis">Project: Vision Transformer Analysis</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/arg-prediction-transformers">Project: ARG Prediction with Transformers</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/yolo-object-tracking">Project: YOLO Object Tracking</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/gan-generation">Project: GAN Generation</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2022</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/deep-q-learning-agent">Project: Deep Q-Learning Agent</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/personalblog/blog/unet-segmentation">Project: U-Net Segmentation</a></li></ul></div></nav></aside><main class="col col--7"><header class="margin-bottom--xl"><h1>4 posts tagged with &quot;PyTorch&quot;</h1><a href="/personalblog/blog/tags">View All Tags</a></header><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/personalblog/blog/hand-gesture-recognition">Project: General Hand Gesture Recognition</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2025-04-15T00:00:00.000Z">April 15, 2025</time> · <!-- -->3 min read</div></header><div class="markdown"><p><a href="https://github.com/ash3327/major-fyp-2024" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/View_Project-Hand%20Gesture%20Recognition-4285F4?style=flat&amp;logo=github&amp;logoColor=white" alt="View Project" class="img_ev3q"></a></p>
<p><a href="https://github.com/ash3327/major-fyp-2024/blob/rework-1/docs/KTL2401_1155175983_1155174636_final_report_term2.pdf" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Report-4285F4?style=flat&amp;logo=github&amp;logoColor=white" alt="Report" class="img_ev3q"></a>
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&amp;logo=pytorch&amp;logoColor=white" alt="PyTorch" class="img_ev3q"></a>
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Computer_Vision-00BFFF?style=flat" alt="Computer Vision" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Contrastive_Learning-FF69B4?style=flat" alt="Contrastive Learning" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Sep%202024-Apr%202025-4285F4?style=flat" alt="Duration" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h2>
<p>This project aims to create a unified, semi-supervised contrastive-learning framework for hand gesture recognition. The framework is designed to adapt efficiently to various downstream tasks, such as human-computer interaction and sign language recognition, with minimal retraining or fine-tuning.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scope-and-applications">Scope and Applications<a href="#scope-and-applications" class="hash-link" aria-label="Direct link to Scope and Applications" title="Direct link to Scope and Applications">​</a></h2>
<blockquote>
<p>[!NOTE]
This section is a summary generated from the <a href="https://github.com/ash3327/major-fyp-2024/blob/rework-1/docs/KTL2401_1155175983_1155174636_final_report_term2.pdf" target="_blank" rel="noopener noreferrer">report</a> by Grok. The contents have been double-checked by the author.</p>
<p>Only this section covers the main content of the report and the remaining sections are about the details of setting up the project and the purpose of specific scripts within the repository.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-areas-explored">Key Areas Explored<a href="#key-areas-explored" class="hash-link" aria-label="Direct link to Key Areas Explored" title="Direct link to Key Areas Explored">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="static-pose-representation-learning">Static-Pose Representation Learning<a href="#static-pose-representation-learning" class="hash-link" aria-label="Direct link to Static-Pose Representation Learning" title="Direct link to Static-Pose Representation Learning">​</a></h4>
<ul>
<li><strong>Objective</strong>: Map hand landmark inputs (shape <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">21 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">21</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span>) into feature embeddings (size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn></mrow><annotation encoding="application/x-tex">128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">128</span></span></span></span>).</li>
<li><strong>Approach</strong>: Compared three encoder architectures:<!-- -->
<ul>
<li>Multi-layer Perceptron (MLP)</li>
<li>Graph Convolutional Network (GCN)</li>
<li>Graph Attention Network (GAT)</li>
</ul>
</li>
<li><strong>Hypotheses Tested</strong>:<!-- -->
<ol>
<li>Graph-based models (GCN and GAT), which leverage edge information, outperform MLP in accuracy and convergence speed. This was evaluated using supervised contrastive loss on the Lexset dataset.</li>
<li>Incorporating a large unlabelled dataset (synthetic MANO data) with curriculum-based augmentations enhances model generalization.</li>
</ol>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="extension-to-dynamic-gesture-recognition">Extension to Dynamic Gesture Recognition<a href="#extension-to-dynamic-gesture-recognition" class="hash-link" aria-label="Direct link to Extension to Dynamic Gesture Recognition" title="Direct link to Extension to Dynamic Gesture Recognition">​</a></h4>
<ul>
<li><strong>Objective</strong>: Extend the contrastive learning approach to recognize dynamic gestures.</li>
<li><strong>Approach</strong>: Utilize sequential architectures like Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) units to model temporal dependencies in gesture sequences.</li>
</ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/project">Project</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/py-torch">PyTorch</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/computer-vision">Computer Vision</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/contrastive-learning">Contrastive Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/deep-learning">Deep Learning</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Project: General Hand Gesture Recognition" href="/personalblog/blog/hand-gesture-recognition"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/personalblog/blog/vision-transformer-analysis">Project: Vision Transformer Analysis</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-04-01T00:00:00.000Z">April 1, 2024</time> · <!-- -->4 min read</div></header><div class="markdown"><p><a href="https://github.com/ash3327/proj-vision-transformer" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/View_Project-Vision%20Transformer%20Analysis-4285F4?style=flat&amp;logo=github&amp;logoColor=white" alt="View Project" class="img_ev3q"></a></p>
<p><a href="https://www.python.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Python-3776AB.svg?logo=python&amp;logoColor=white" alt="Python" class="img_ev3q"></a>
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/PyTorch-EE4C2C.svg?logo=pytorch&amp;logoColor=white" alt="PyTorch" class="img_ev3q"></a>
<a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Paper-UNet-green?logo=arxiv&amp;color=green" alt="UNet" class="img_ev3q"></a>
<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Paper-ResNet-green?logo=arxiv&amp;color=green" alt="ResNet" class="img_ev3q"></a>
<a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Paper-ViT-green?logo=arxiv&amp;color=green" alt="ViT" class="img_ev3q"></a>
<a href="https://github.com/facebookresearch/deit" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Model-DeiT-orange?logo=github&amp;color=orange" alt="DeiT" class="img_ev3q"></a>
<a href="https://github.com/yitu-opensource/T2T-ViT" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Model-T2T-orange?logo=github&amp;color=orange" alt="T2T" class="img_ev3q"></a>
<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Dataset-CIFAR10-blue.svg" alt="Dataset | CIFAR10" class="img_ev3q"></a>
<a href="https://cs.stanford.edu/~acoates/stl10/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Dataset-STL10-blue.svg" alt="Dataset | STL10" class="img_ev3q"></a>
<a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Dataset-Cityscapes-blue.svg" alt="Dataset | Cityscapes" class="img_ev3q"></a>
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Last%20Update-April%202024-green.svg" alt="Last Update | April 2024" class="img_ev3q"></p>
<p>This is the final project for the course <strong>AIST4010</strong>. More details on the project can be found in the report. This project is done in April 2024.</p>
<p><strong>Report</strong>: <a href="https://github.com/ash3327/proj-vision-transformer/blob/master/project-final-report-1155175983.pdf" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Final%20Report-blue.svg" alt="Report" class="img_ev3q"></a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="project-goals">Project Goals<a href="#project-goals" class="hash-link" aria-label="Direct link to Project Goals" title="Direct link to Project Goals">​</a></h3>
<p>The project investigates the <strong>generalizability of Vision Transformers (ViTs)</strong> compared to Convolutional Neural Networks (CNNs) for <strong>small-scale computer vision tasks</strong>. While ViTs excel in large datasets, they struggle with smaller ones. This work evaluates and compares the performance of models like ResNet, ViT, DeiT, and T2T-ViT on classification tasks using small subsets of CIFAR-10 and STL-10 datasets.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-contributions">Key Contributions<a href="#key-contributions" class="hash-link" aria-label="Direct link to Key Contributions" title="Direct link to Key Contributions">​</a></h3>
<ol>
<li><strong>Scalability Analysis</strong>: Demonstrated performance degradation of ViTs with reduced dataset sizes, showing CNNs are more effective for small datasets.</li>
<li><strong>Computational Efficiency</strong>: Analyzed training iterations and time-to-convergence, highlighting that ViTs, while converging faster, still lack efficiency due to lower accuracy on small datasets.</li>
<li><strong>Comparison of Architectures</strong>: Implemented and trained models with similar parameter counts for fair performance evaluations.</li>
</ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/project">Project</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/py-torch">PyTorch</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/computer-vision">Computer Vision</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/vision-transformers">Vision Transformers</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Project: Vision Transformer Analysis" href="/personalblog/blog/vision-transformer-analysis"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/personalblog/blog/gan-generation">Project: GAN Generation</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-06-01T00:00:00.000Z">June 1, 2023</time> · <!-- -->2 min read</div></header><div class="markdown"><p><a href="https://github.com/ash3327/GAN-self-learn-v1" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/View_Project-GAN%20Generation-4285F4?style=flat&amp;logo=github&amp;logoColor=white" alt="View Project" class="img_ev3q"></a></p>
<p><a href="https://www.python.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Python-3776AB.svg?logo=python&amp;logoColor=white" alt="Python" class="img_ev3q"></a>
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/PyTorch-EE4C2C.svg?logo=pytorch&amp;logoColor=white" alt="PyTorch" class="img_ev3q"></a>
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/GAN-Generative%20Adversarial%20Networks-blueviolet.svg" alt="Generative Adversarial Networks" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Dataset-MNIST-blue.svg" alt="MNIST Dataset" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Last%20Updated-August%202022-green.svg" alt="Last Updated: August 2022" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="backup-of-gan-learning-project-august-2022">Backup of GAN Learning Project (August 2022)<a href="#backup-of-gan-learning-project-august-2022" class="hash-link" aria-label="Direct link to Backup of GAN Learning Project (August 2022)" title="Direct link to Backup of GAN Learning Project (August 2022)">​</a></h2>
<blockquote>
<p>[!NOTE]
The project explores various GAN architectures and improvements through iterative versions.</p>
</blockquote>
<blockquote>
<p>[!IMPORTANT]
This project is a personal learning exercise in understanding and implementing different GAN techniques.</p>
</blockquote>
<p>This project re-implemented GAN, WGAN and conditional GAN and explored the typical problems that occurred with GAN-based architectures like mode collapse and sensitivity to hyperparameters.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/project">Project</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/py-torch">PyTorch</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/gan">GAN</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/deep-learning">Deep Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/generative-models">Generative Models</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Project: GAN Generation" href="/personalblog/blog/gan-generation"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/personalblog/blog/unet-segmentation">Project: U-Net Segmentation</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-08-04T00:00:00.000Z">August 4, 2022</time> · <!-- -->4 min read</div></header><div class="markdown"><p><a href="https://github.com/ash3327/ImageSegmentation-UNet" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/View_Project-U--Net%20Segmentation-4285F4?style=flat&amp;logo=github&amp;logoColor=white" alt="View Project" class="img_ev3q"></a></p>
<p><a href="https://www.python.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Python-3776AB.svg?logo=python&amp;logoColor=white" alt="Python" class="img_ev3q"></a>
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/PyTorch-EE4C2C.svg?logo=pytorch&amp;logoColor=white" alt="PyTorch" class="img_ev3q"></a>
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Artificial%20Intelligence%20(AI)-orange.svg?logo=ai&amp;logoColor=white" alt="Artificial Intelligence (AI)" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Image%20Segmentation-red.svg?logo=segmentation&amp;logoColor=white" alt="Image Segmentation" class="img_ev3q">
<a href="https://www.kaggle.com/competitions/carvana-image-masking-challenge" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Kaggle-Carvana%20Image%20Masking%20Challenge-blue.svg?logo=kaggle&amp;logoColor=white" alt="Carvana Image Masking Challenge" class="img_ev3q"></a>
<a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Dataset-Cityscapes%20Dataset-00BFFF.svg?logo=data:image/png;base64,iVBORw0KGg&amp;logoColor=white" alt="Cityscapes Dataset" class="img_ev3q"></a>
<img decoding="async" loading="lazy" src="https://img.shields.io/badge/Last%20Updated-December%202023-green.svg" alt="Last Updated: December 2023" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="backup-of-old-project-december-2023">Backup of Old Project (December 2023)<a href="#backup-of-old-project-december-2023" class="hash-link" aria-label="Direct link to Backup of Old Project (December 2023)" title="Direct link to Backup of Old Project (December 2023)">​</a></h2>
<p>This is a backup of an old project focused on training a U-Net model from scratch for semantic segmentation from scratch on the Cityscapes dataset and Carvana dataset. The images are DOWNSCALED to speed up the training process for learning purposes.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/project">Project</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/py-torch">PyTorch</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/segmentation">Segmentation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/computer-vision">Computer Vision</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/personalblog/blog/tags/deep-learning">Deep Learning</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Project: U-Net Segmentation" href="/personalblog/blog/unet-segmentation"><b>Read more</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Sam K. H. Tam. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>