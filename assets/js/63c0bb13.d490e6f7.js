"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7767],{4676:e=>{e.exports=JSON.parse('{"permalink":"/personalblog/blog/vision-transformer-analysis","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-04-01-vision-transformer-analysis.md","source":"@site/blog/2024-04-01-vision-transformer-analysis.md","title":"Project: Vision Transformer Analysis","description":"Comparative study of Vision Transformers vs CNNs on small datasets","date":"2024-04-01T00:00:00.000Z","tags":[{"inline":true,"label":"Project","permalink":"/personalblog/blog/tags/project"},{"inline":false,"label":"PyTorch","permalink":"/personalblog/blog/tags/pytorch"},{"inline":true,"label":"Computer Vision","permalink":"/personalblog/blog/tags/computer-vision"},{"inline":true,"label":"Machine Learning","permalink":"/personalblog/blog/tags/machine-learning"},{"inline":true,"label":"Vision Transformers","permalink":"/personalblog/blog/tags/vision-transformers"}],"readingTime":3.655,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Project: Vision Transformer Analysis","description":"Comparative study of Vision Transformers vs CNNs on small datasets","slug":"vision-transformer-analysis","tags":["Project","PyTorch","Computer Vision","Machine Learning","Vision Transformers"],"image":"/img//img/docs/vit/vit/image4.png"},"unlisted":false,"prevItem":{"title":"Project: P2P Communication App","permalink":"/personalblog/blog/p2p-communication-app"},"nextItem":{"title":"Project: ARG Prediction with Transformers","permalink":"/personalblog/blog/arg-prediction-transformers"}}')},5375:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>l,contentTitle:()=>a,default:()=>g,frontMatter:()=>n,metadata:()=>t,toc:()=>c});var t=r(4676),i=r(4848),o=r(8453);const n={title:"Project: Vision Transformer Analysis",description:"Comparative study of Vision Transformers vs CNNs on small datasets",slug:"vision-transformer-analysis",tags:["Project","PyTorch","Computer Vision","Machine Learning","Vision Transformers"],image:"/img//img/docs/vit/vit/image4.png"},a="Project Vision Transformer",l={authorsImageUrls:[]},c=[{value:"Overview",id:"overview",level:2},{value:"Project Goals",id:"project-goals",level:3},{value:"Key Contributions",id:"key-contributions",level:3}];function h(e){const s={a:"a",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.a,{href:"https://github.com/ash3327/proj-vision-transformer",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/View_Project-Vision%20Transformer%20Analysis-4285F4?style=for-the-badge&logo=github&logoColor=white",alt:"View Project"})})," ",(0,i.jsx)(s.a,{href:"https://github.com/ash3327/proj-vision-transformer/blob/master/project-final-report-1155175983.pdf",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Final%20Report-blue.svg?style=for-the-badge",alt:"Report"})})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.a,{href:"https://www.python.org/",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Python-3776AB.svg?logo=python&logoColor=white",alt:"Python"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://pytorch.org/",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/PyTorch-EE4C2C.svg?logo=pytorch&logoColor=white",alt:"PyTorch"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1505.04597",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Paper-UNet-green?logo=arxiv&color=green",alt:"UNet"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1512.03385",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Paper-ResNet-green?logo=arxiv&color=green",alt:"ResNet"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2010.11929",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Paper-ViT-green?logo=arxiv&color=green",alt:"ViT"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://github.com/facebookresearch/deit",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Model-DeiT-orange?logo=github&color=orange",alt:"DeiT"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://github.com/yitu-opensource/T2T-ViT",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Model-T2T-orange?logo=github&color=orange",alt:"T2T"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://www.cs.toronto.edu/~kriz/cifar.html",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Dataset-CIFAR10-blue.svg",alt:"Dataset | CIFAR10"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://cs.stanford.edu/~acoates/stl10/",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Dataset-STL10-blue.svg",alt:"Dataset | STL10"})}),"\r\n",(0,i.jsx)(s.a,{href:"https://www.cityscapes-dataset.com/",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Dataset-Cityscapes-blue.svg",alt:"Dataset | Cityscapes"})}),"\r\n",(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Last%20Update-April%202024-green.svg",alt:"Last Update | April 2024"})]}),"\n",(0,i.jsxs)(s.p,{children:["This is the final project for the course ",(0,i.jsx)(s.strong,{children:"AIST4010"}),". More details on the project can be found in the report. This project is done in April 2024."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Report"}),": ",(0,i.jsx)(s.a,{href:"https://github.com/ash3327/proj-vision-transformer/blob/master/project-final-report-1155175983.pdf",children:(0,i.jsx)(s.img,{src:"https://img.shields.io/badge/Final%20Report-blue.svg",alt:"Report"})})]}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(s.h3,{id:"project-goals",children:"Project Goals"}),"\n",(0,i.jsxs)(s.p,{children:["The project investigates the ",(0,i.jsx)(s.strong,{children:"generalizability of Vision Transformers (ViTs)"})," compared to Convolutional Neural Networks (CNNs) for ",(0,i.jsx)(s.strong,{children:"small-scale computer vision tasks"}),". While ViTs excel in large datasets, they struggle with smaller ones. This work evaluates and compares the performance of models like ResNet, ViT, DeiT, and T2T-ViT on classification tasks using small subsets of CIFAR-10 and STL-10 datasets."]}),"\n",(0,i.jsx)(s.h3,{id:"key-contributions",children:"Key Contributions"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Scalability Analysis"}),": Demonstrated performance degradation of ViTs with reduced dataset sizes, showing CNNs are more effective for small datasets."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Computational Efficiency"}),": Analyzed training iterations and time-to-convergence, highlighting that ViTs, while converging faster, still lack efficiency due to lower accuracy on small datasets."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Comparison of Architectures"}),": Implemented and trained models with similar parameter counts for fair performance evaluations."]}),"\n"]})]})}function g(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,s,r)=>{r.d(s,{R:()=>n,x:()=>a});var t=r(6540);const i={},o=t.createContext(i);function n(e){const s=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:n(e.components),t.createElement(o.Provider,{value:s},e.children)}}}]);