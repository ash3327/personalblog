"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[296],{348:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"rl/dqn/index","title":"Deep Q-Network (DQN)","description":"","source":"@site/docs/ai/rl/dqn/index.md","sourceDirName":"rl/dqn","slug":"/rl/dqn/","permalink":"/personalblog/docs/ai/rl/dqn/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Basic Theory of Reinforcement Learning","permalink":"/personalblog/docs/ai/rl/basic/"}}');var o=t(4848),s=t(8453);const i={sidebar_position:3},a="Deep Q-Network (DQN)",c={},d=[];function l(e){const n={h1:"h1",header:"header",...(0,s.R)(),...e.components};return(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"deep-q-network-dqn",children:"Deep Q-Network (DQN)"})})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var r=t(6540);const o={},s=r.createContext(o);function i(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);