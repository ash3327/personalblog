"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4583],{7555:(e,i,t)=>{t.r(i),t.d(i,{default:()=>w});var a=t(6540);const n={highlighted:"highlighted_zgM8",profile:"profile_OhUD",badges:"badges_T7Sn"};var s=t(1410);const r={highlighted:"highlighted_EHZG",badges:"badges_NiKE",sections:"sections_ebOp",section:"section_qTu_",cardsContainer:"cardsContainer_sHCX",card:"card_YtbC",date:"date_BKZ3",awardImage:"awardImage_VvTf",awardLink:"awardLink_wtN8",profile:"profile_ctWG"},o=[{name:"CSE Outstanding Academic Performance (Bronze)",year:"2023-24"},{name:"Dean's List",year:"2021-24"},{name:"Academic Secretary",year:"2022",description:"The 43rd Bethlehem Hall Resident Association"}],l=[{institution:"The Chinese University of Hong Kong",degree:"Bachelor of Engineering in Artificial Intelligence: Systems and Technology",date:"Sep 2021 - Expected Aug 2025",description:["Current GPA: 3.755 / 4.0","Major GPA: 3.795 / 4.0"]},{institution:"Bishop Hall Jubilee School",degree:"Hong Kong Diploma of Secondary Education",date:"Sep 2015 - Aug 2021",description:["DSE(2021):","5** in Maths and Physics,","5* in Chemistry, ICT, and Maths (M2)","5 in Chinese and English"]}],c=[{title:"Machine Learning Intern",company:"Glassbox AI Limited, Sha Tin",date:"Jun 2024 - Nov 2024",description:["Backend pipeline for automated data fetching from APIs and LLM inference (Python, Flask, MySQL)","Implemented and trained RNN-based models for sign language translation tasks","Researched and optimized methods for temporal alignment on gesture sequences"]}],d=[{title:"Programming",badges:[{name:"Python",color:"3776AB",logo:"python",logoColor:"white"},{name:"Java",color:"ED8B00",logo:"openjdk",logoColor:"white"},{name:"C/C++",color:"00599C",logo:"cplusplus",logoColor:"gray"}]},{title:"Web & Backend",badges:[{name:"Flask",color:"000000",logo:"flask",logoColor:"white"},{name:"MySQL",color:"4479A1",logo:"mysql",logoColor:"white"},{name:"Git",color:"F05032",logo:"git",logoColor:"white"},{name:"Linux",color:"FCC624",logo:"linux",logoColor:"black"}]},{title:"AI/ML",badges:[{name:"PyTorch",color:"EE4C2C",logo:"pytorch",logoColor:"white"},{name:"TensorFlow",color:"FF6F00",logo:"tensorflow",logoColor:"white"},{name:"Pandas",color:"250458",logo:"pandas",logoColor:"white"},{name:"NumPy",color:"013243",logo:"numpy",logoColor:"white"}]},{title:"Languages",badges:[{name:"English",color:"blue",level:"Fluent"},{name:"Cantonese",color:"4285F4",level:"Native"},{name:"Mandarin",color:"4285F4",level:"Native"}]}];var g=t(4848);function h(){const e=(0,a.useRef)(null),i=(0,a.useRef)(null),t=(0,a.useRef)(null);return(0,a.useEffect)((()=>{const a=[e.current,i.current,t.current],n=e=>{if(!e)return;const i=e.getElementsByClassName(r.card),t=e.getBoundingClientRect(),a=t.left+t.width/2,n=t.width/2;Array.from(i).forEach((e=>{const i=e.getBoundingClientRect(),t=i.left+i.width/2,s=Math.abs(t-a),r=Math.min(s/n,1),o=1-.2*r,l=1-.3*r;e.style.transform=`scale(${o})`,e.style.opacity=`${l}`}))},s=()=>{a.forEach((e=>{e&&requestAnimationFrame((()=>n(e)))}))},o=()=>{a.forEach((e=>{e&&requestAnimationFrame((()=>n(e)))}))};return a.forEach((e=>{e&&(n(e),e.addEventListener("scroll",s),window.addEventListener("resize",o))})),()=>{a.forEach((e=>{e&&(e.removeEventListener("scroll",s),window.removeEventListener("resize",o))}))}}),[]),(0,g.jsx)("section",{className:r.highlighted,children:(0,g.jsxs)("div",{className:r.sections,children:[(0,g.jsxs)("div",{className:r.section,children:[(0,g.jsx)("h2",{children:"\ud83d\udcbc Experiences"}),(0,g.jsxs)("div",{className:r.cardsContainer,ref:e,children:[c.map(((e,i)=>(0,g.jsxs)("div",{className:r.card,children:[(0,g.jsx)("h3",{children:e.title}),(0,g.jsx)("h4",{children:e.company}),(0,g.jsx)("p",{className:r.date,children:e.date}),(0,g.jsx)("ul",{children:e.description.map(((e,i)=>(0,g.jsx)("li",{children:e},i)))})]},`work-${i}`))),l.map(((e,i)=>(0,g.jsxs)("div",{className:r.card,children:[(0,g.jsx)("h3",{children:e.degree}),(0,g.jsx)("h4",{children:e.institution}),(0,g.jsx)("p",{className:r.date,children:e.date}),(0,g.jsx)("ul",{children:e.description.map(((e,i)=>(0,g.jsx)("li",{children:e},i)))})]},`edu-${i}`)))]})]}),(0,g.jsxs)("div",{className:r.section,children:[(0,g.jsx)("h2",{children:"\ud83c\udfc6 Awards"}),(0,g.jsx)("div",{className:r.cardsContainer,ref:i,children:o.map(((e,i)=>(0,g.jsxs)("div",{className:r.card,children:[(0,g.jsx)("h3",{children:e.name}),(0,g.jsx)("p",{className:r.date,children:e.year}),e.description&&(0,g.jsx)("p",{children:e.description}),e.image&&(0,g.jsx)("div",{className:r.awardImage,children:(0,g.jsx)("img",{src:e.image,alt:e.name})}),e.link&&(0,g.jsx)("a",{href:e.link,target:"_blank",rel:"noopener noreferrer",className:r.awardLink,children:(0,g.jsx)("img",{src:"https://img.shields.io/badge/Link-4285F4?style=flat&logo=link&logoColor=white",alt:"Link"})})]},i)))})]}),(0,g.jsxs)("div",{className:r.section,children:[(0,g.jsx)("h2",{children:"\ud83d\udee0\ufe0f Skills"}),(0,g.jsx)("div",{className:r.cardsContainer,ref:t,children:d.map(((e,i)=>(0,g.jsxs)("div",{className:r.card,children:[(0,g.jsx)("h3",{children:e.title}),(0,g.jsx)("div",{className:r.badges,children:e.badges.map(((e,i)=>(0,g.jsx)("img",{src:`https://img.shields.io/badge/${e.name}${e.level?`-${e.level}`:""}-${e.color}?style=flat${e.logo?`&logo=${e.logo}`:""}${e.logoColor?`&logoColor=${e.logoColor}`:""}`,alt:e.name,style:{height:"24px"}},i)))})]},i)))})]})]})})}var m=t(5604),u=t(4164),p=t(9303);const f={features:"features_t9lD",sectionHeader:"sectionHeader_fLny",filterTags:"filterTags_DSCZ",filterTag:"filterTag_hrOo",active:"active_CrSe",moreTags:"moreTags_Olzf",featuresContainer:"featuresContainer_Xi_N",featureCard:"featureCard_QAQr",highlightedCard:"highlightedCard_MGvl",highlightedBadge:"highlightedBadge_C8q0",featureImage:"featureImage_n6ct",featureContent:"featureContent_StuG",date:"date_WBEZ",badges:"badges_Lf3k",badge:"badge_GpeJ",githubBadge:"githubBadge_YHt4",githubIcon:"githubIcon_eRUJ"},b=[{title:"FYP: Invariant Hand Gesture Representation Learning with Augmented Contrastive Learning",image:"/img/docs/fyp/image.png",description:"Unified contrastive learning framework for hand gesture recognition with curriculum-based augmentation",link:"/blog/hand-gesture-recognition",githubLink:"https://github.com/ash3327/major-fyp-2024",badges:["PyTorch","Computer Vision","Contrastive Learning"],slug:"hand-gesture-recognition",highlighted:!0,date:"Sep 2024 - Apr 2025"},{title:"Named Entity Recognition Project",image:"/img/placeholder.png",description:"This project aims to explore methodologies related to Named Entity Recognition",link:"/blog/ner-project",githubLink:"https://github.com/ash3327/aist3120-ner-project",badges:["HuggingFace","Natural Language Processing","Transformers"],slug:"ner-project",date:"Mar 2024 - Apr 2024"},{title:"Vision Transformer Analysis",image:"/img/docs/vit/image4.png",description:"Comparative study of Vision Transformers vs CNNs on small datasets",link:"/blog/vision-transformer-analysis",githubLink:"https://github.com/ash3327/proj-vision-transformer",badges:["PyTorch","Computer Vision"],slug:"vision-transformer-analysis",highlighted:!0,date:"Jan 2024 - Apr 2024"},{title:"ARG Prediction with Transformers",image:"/img/docs/prottrans/image.png",description:"Fine-tuned ProtTrans model for antibiotic resistance gene classification with 0.94 F-score",link:"/blog/arg-prediction-transformers",githubLink:"https://github.com/ash3327/aist4010-coursework-asm2-protein-transformer",badges:["PyTorch","Transformers","Bioinformatics"],slug:"arg-prediction-transformers",date:"Feb 2024 - Mar 2024"},{title:"P2P Communication App",image:"/img/docs/p2p/image.png",description:"Real-time audio/video streaming with optimized packet synchronization",link:"/blog/p2p-communication-app",githubLink:"https://github.com/ash3327/Peer-to-Peer-Communication-App",badges:["Python","Flask","Socket"],slug:"p2p-communication-app",date:"Jan 2024 - Apr 2024"},{title:"U-Net Segmentation",image:"/img/docs/unet/unet_1.png",description:"99.55% pixel accuracy on Carvana dataset",link:"/blog/unet-segmentation",githubLink:"https://github.com/ash3327/ImageSegmentation-UNet",badges:["PyTorch","Computer Vision","Segmentation"],slug:"unet-segmentation",date:"Aug 2023"},{title:"Deep Q-Learning Agent",image:"https://github.com/ash3327/ash3327/assets/86100752/60f36fa1-d6fd-490b-b275-19bb1cbe9715",description:"Reinforcement learning agent achieving 30\xd7 higher performance in custom Gym environment",link:"/blog/deep-q-learning-agent",githubLink:"https://github.com/ash3327/SnowFight",badges:["Python","Gymnasium","PyTorch","Reinforcement Learning"],slug:"deep-q-learning-agent",highlighted:!0,date:"Oct 2022 - Dec 2022"},{title:"YOLO Object Tracking",image:"/img/docs/yolo-1/vid3.gif",description:"Improved instance tracking with custom algorithm from outputs of YOLOv8",link:"/blog/yolo-object-tracking",githubLink:"https://github.com/ash3327/ObjectDetection-v1",badges:["YOLO","Object Detection"],slug:"yolo-object-tracking",date:"Jun 2023 - Apr 2024"},{title:"GAN Generation",image:"/img/docs/gan/v5.gif",description:"Learning project that re-implemented GAN, WGAN and conditional GAN and explored the typical problems that occurred with GAN-based architectures like mode collapse and sensitivity to hyperparameters.",link:"/blog/gan-generation",githubLink:"https://github.com/ash3327/GAN-self-learn-v1",badges:["PyTorch","GAN","Computer Vision"],slug:"gan-generation",date:"Aug 2022"},{title:'Event-Planning App "Oasis"',image:"/img/docs/oasis/image.png",description:"Android event planning app with robust notification system and SQL database",link:"/blog/oasis-event-planning-app",githubLink:"https://github.com/ash3327/OasisPlanner/tree/development",badges:["Java","Android","RoomDB"],slug:"oasis-event-planning-app",highlighted:!0,date:"Mar 2023 - Jan 2024"}];var j=t(797);const C=["all","featured","computer-vision","reinforcement-learning","transformers","software-development"];function v(e){let{title:i,image:t,description:a,link:n,githubLink:s,badges:r,highlighted:o,date:l}=e;const{siteConfig:c}=(0,j.A)();return(0,g.jsxs)("div",{className:(0,u.A)(f.featureCard,o&&f.highlightedCard),children:[o&&(0,g.jsx)("div",{className:f.highlightedBadge,children:"Featured"}),(0,g.jsx)("div",{className:f.featureImage,children:(0,g.jsx)("img",{src:t.startsWith("/")?`/${c.projectName}${t}`:t,alt:i})}),(0,g.jsxs)("div",{className:f.featureContent,children:[(0,g.jsx)(p.A,{as:"h3",children:(0,g.jsx)("a",{href:n.startsWith("/")?`/${c.projectName}${n}`:n,children:i})}),(0,g.jsx)("p",{className:f.date,children:l}),(0,g.jsx)("p",{children:a}),(0,g.jsxs)("div",{className:f.badges,children:[r.map(((e,i)=>(0,g.jsx)("a",{href:`/personalblog/blog/tags/${e.toLowerCase().replace(/\s+/g,"-")}`,className:f.badge,children:e},i))),(0,g.jsxs)("a",{href:s,className:f.githubBadge,target:"_blank",rel:"noopener noreferrer",children:[(0,g.jsx)(m.hL4,{className:f.githubIcon})," GitHub"]})]})]})]})}function x(){const e=(0,a.useRef)(null),[i,t]=(0,a.useState)("featured"),n=b.filter((e=>{switch(i){case"featured":return e.highlighted;case"computer-vision":return e.badges.some((e=>e.toLowerCase().includes("vision")||e.toLowerCase().includes("yolo")||e.toLowerCase().includes("segmentation")));case"reinforcement-learning":return e.badges.some((e=>e.toLowerCase().includes("reinforcement")||e.toLowerCase().includes("gymnasium")));case"transformers":return e.badges.some((e=>e.toLowerCase().includes("transformer")||e.toLowerCase().includes("huggingface")));case"software-development":return e.badges.some((e=>e.toLowerCase().includes("java")||e.toLowerCase().includes("android")||e.toLowerCase().includes("flask")||e.toLowerCase().includes("socket")));default:return!0}}));return(0,a.useEffect)((()=>{const i=e.current;if(!i)return;const t=()=>{const e=i.getElementsByClassName(f.featureCard),t=i.getBoundingClientRect(),a=t.left+t.width/2;Array.from(e).forEach((e=>{const i=e.getBoundingClientRect(),n=i.left+i.width/2,s=Math.abs(n-a),r=t.width/2,o=1-s/r*.3,l=1-s/r*.5;e.style.transform=`scale(${o})`,e.style.opacity=`${l}`}))};return t(),i.addEventListener("scroll",t),window.addEventListener("resize",t),()=>{i.removeEventListener("scroll",t),window.removeEventListener("resize",t)}}),[i]),(0,g.jsxs)("section",{className:f.features,children:[(0,g.jsxs)("div",{className:f.sectionHeader,children:[(0,g.jsx)("h2",{children:"\ud83d\ude80 Projects"}),(0,g.jsxs)("div",{className:f.filterTags,children:[C.map((e=>(0,g.jsx)("button",{className:(0,u.A)(f.filterTag,i===e&&f.active),onClick:()=>t(e),children:e.replace("-"," ").replace(/(^\w|\s\w)/g,(e=>e.toUpperCase()))},e))),(0,g.jsx)("button",{className:f.filterTag,children:(0,g.jsx)("a",{href:"/personalblog/blog/tags",children:"More Tags"})})]})]}),(0,g.jsx)("div",{className:f.featuresContainer,ref:e,children:n.map(((e,i)=>(0,g.jsx)(v,{...e},i)))})]})}function w(){return(0,g.jsx)(s.A,{title:"Home",description:"Sam's Portfolio - Machine Learning Engineer & Software Developer",children:(0,g.jsxs)("main",{children:[(0,g.jsx)("section",{className:n.highlighted,children:(0,g.jsxs)("div",{className:n.profile,children:[(0,g.jsx)("h1",{children:"Hi there\ud83d\udc4b, I'm Sam"}),(0,g.jsxs)("div",{className:n.badges,children:[(0,g.jsx)("a",{href:"https://github.com/ash3327",children:(0,g.jsx)("img",{src:"https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white",alt:"GitHub"})}),(0,g.jsx)("a",{href:"https://www.linkedin.com/in/khtam-51a008256",children:(0,g.jsx)("img",{src:"https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white",alt:"LinkedIn"})}),(0,g.jsx)("a",{href:"/personalblog/img/docs/_resumes/CV_TAMKAHO_AI.pdf",target:"_blank",rel:"noopener noreferrer",children:(0,g.jsx)("img",{src:"https://img.shields.io/badge/Resume%20(AI)-4B0082?style=for-the-badge&logo=google-drive&logoColor=white",alt:"Resume"})})]}),(0,g.jsxs)("p",{children:["Fresh Graduate Graduating with B.Eng. in Artificial Intelligence at CUHK (July 2025)",(0,g.jsx)("br",{}),"GPA: 3.755/4.00 (overall), 3.795/4.00 (major) | Dean's List 2021-24",(0,g.jsx)("br",{}),"Interests in Machine Learning (Computer Vision and RL)"]})]})}),(0,g.jsx)(x,{}),(0,g.jsx)(h,{})]})})}}}]);