"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2637],{836:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>g});var r=n(3041),i=n(4848),o=n(8453);const a={title:"Project: Deep Q-Learning Agent",description:"Reinforcement learning agent achieving 30\xd7 higher performance in custom Gym environment",slug:"deep-q-learning-agent",tags:["Project","Python","Gymnasium","Reinforcement Learning","Deep Learning"],image:"https://github.com/ash3327/ash3327/assets/86100752/60f36fa1-d6fd-490b-b275-19bb1cbe9715"},s='Deep Q-Learning Shooter Game Project "SnowFight"',l={authorsImageUrls:[]},g=[{value:"Overview",id:"overview",level:2}];function h(e){const t={a:"a",h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://github.com/ash3327/SnowFight",children:(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/View_Project-Deep%20Q--Learning%20Agent-4285F4?style=for-the-badge&logo=github&logoColor=white",alt:"View Project"})})," ",(0,i.jsx)(t.a,{href:"https://github.com/ash3327/SnowFight/blob/master/project%20report%20-%20group%205.pdf",children:(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Report-4285F4?style=for-the-badge&logo=github&logoColor=white&link=https://github.com/ash3327/SnowFight/blob/master/project%20report%20-%20group%205.pdf",alt:"Report"})})]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.python.org/",children:(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white",alt:"Python"})}),"\r\n",(0,i.jsx)(t.a,{href:"https://gymnasium.farama.org/index.html",children:(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Gymnasium-8B9467?style=flat&logo=openai",alt:"Gymnasium"})}),"\r\n",(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Reinforcement_Learning-00BFFF?style=flat",alt:"Reinforcement Learning"}),"\r\n",(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Group_Project-FF9900?style=flat",alt:"Group Project"}),"\r\n",(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Last_Updated-December_2022-green?style=flat",alt:"Last Updated"})]}),"\n",(0,i.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Created a Gym environment of a simple third-person shooter game in Python"}),"\n",(0,i.jsx)(t.li,{children:"Implemented a simple Deep-Q Network with PyTorch to train agents to master at the game (left image)"}),"\n",(0,i.jsx)(t.li,{children:"Fine-tuned the hyperparameters of the agent, achieving average kill streak of 7 (right image, top) and lengthend the survival duration by 4 times (right image, bottom), which significantly better than the random baseline of 0.22 kills on average."}),"\n",(0,i.jsx)(t.li,{children:"Explored how deep-Q learning models handle a variable quantity of moving objects, i.e. the bullets and enemies, and relevant adjustments to the reward functions and representations of the observation space needed."}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Report:"}),"\xa0",(0,i.jsx)(t.a,{href:"https://github.com/ash3327/SnowFight/blob/master/project%20report%20-%20group%205.pdf",children:(0,i.jsx)(t.img,{src:"https://img.shields.io/badge/Report-4285F4?style=flat&logo=github&logoColor=white&link=https://github.com/ash3327/SnowFight/blob/master/project%20report%20-%20group%205.pdf",alt:"Report"})})]}),"\n",(0,i.jsx)("img",{src:"https://github.com/ash3327/ash3327/assets/86100752/60f36fa1-d6fd-490b-b275-19bb1cbe9715",width:"300",height:"300"}),"\n",(0,i.jsx)("img",{src:"https://github.com/ash3327/ash3327/assets/86100752/9ac9a3e3-8e36-436c-bbd9-48b80c06e2d6",width:"400"})]})}function c(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},3041:e=>{e.exports=JSON.parse('{"permalink":"/personalblog/blog/deep-q-learning-agent","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2022-12-01-deep-q-learning-agent.md","source":"@site/blog/2022-12-01-deep-q-learning-agent.md","title":"Project: Deep Q-Learning Agent","description":"Reinforcement learning agent achieving 30\xd7 higher performance in custom Gym environment","date":"2022-12-01T00:00:00.000Z","tags":[{"inline":true,"label":"Project","permalink":"/personalblog/blog/tags/project"},{"inline":true,"label":"Python","permalink":"/personalblog/blog/tags/python"},{"inline":true,"label":"Gymnasium","permalink":"/personalblog/blog/tags/gymnasium"},{"inline":true,"label":"Reinforcement Learning","permalink":"/personalblog/blog/tags/reinforcement-learning"},{"inline":true,"label":"Deep Learning","permalink":"/personalblog/blog/tags/deep-learning"}],"readingTime":1.915,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Project: Deep Q-Learning Agent","description":"Reinforcement learning agent achieving 30\xd7 higher performance in custom Gym environment","slug":"deep-q-learning-agent","tags":["Project","Python","Gymnasium","Reinforcement Learning","Deep Learning"],"image":"https://github.com/ash3327/ash3327/assets/86100752/60f36fa1-d6fd-490b-b275-19bb1cbe9715"},"unlisted":false,"prevItem":{"title":"Project: YOLO Object Tracking","permalink":"/personalblog/blog/yolo-object-tracking"},"nextItem":{"title":"Project: GAN Generation","permalink":"/personalblog/blog/gan-generation"}}')},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var r=n(6540);const i={},o=r.createContext(i);function a(e){const t=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);