"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[296],{348:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"rl/dqn/index","title":"Deep Q-Network (DQN)","description":"","source":"@site/docs/ai/rl/dqn/index.md","sourceDirName":"rl/dqn","slug":"/rl/dqn/","permalink":"/blog/docs/ai/rl/dqn/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Basic Theory of Reinforcement Learning","permalink":"/blog/docs/ai/rl/basic/"}}');var o=n(4848),s=n(8453);const i={sidebar_position:3},a="Deep Q-Network (DQN)",c={},d=[];function l(e){const t={h1:"h1",header:"header",...(0,s.R)(),...e.components};return(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"deep-q-network-dqn",children:"Deep Q-Network (DQN)"})})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var r=n(6540);const o={},s=r.createContext(o);function i(e){const t=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(s.Provider,{value:t},e.children)}}}]);